{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Retrieval Recency Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:03:50.111118Z",
     "start_time": "2025-05-08T14:03:48.587096Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import DATA_DIR\n",
    "from unbiasai.utils import initialize_llm, generate_embeddings, insert_documents, retrieve, get_documents_from_supabase, convert_to_doc_objects, create_reranking_prompt, perform_llm_reranking, format_results, extract_created_datetime\n",
    "from supabase import create_client, Client\n",
    "from unbiasai.connection import create_supabase_client\n",
    "from dtsc_queries.retrieval_recency import test_queries\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from datetime import datetime\n",
    "\n",
    "from unbiasai.config import ENVFILE\n",
    "load_dotenv(ENVFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:03:50.119111Z",
     "start_time": "2025-05-02T14:26:28.806800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / 'recency_test.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create subset of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:03:50.140801Z",
     "start_time": "2025-05-02T14:26:28.818492Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: gpt\n",
      "Error initializing gpt: initialize_llm() takes 1 positional argument but 2 were given\n",
      "Initializing model: claude\n",
      "Error initializing claude: initialize_llm() takes 1 positional argument but 2 were given\n",
      "Initializing model: mistral\n",
      "Error initializing mistral: initialize_llm() takes 1 positional argument but 2 were given\n",
      "Initializing model: cohere\n",
      "Error initializing cohere: initialize_llm() takes 1 positional argument but 2 were given\n",
      "Initializing model: deepseek\n",
      "Error initializing deepseek: initialize_llm() takes 1 positional argument but 2 were given\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "models = [\"gpt\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "\n",
    "for model_name in models:\n",
    "    initialized_models[model_name] = initialize_llm(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:03:50.166492Z",
     "start_time": "2025-05-02T14:26:28.825871Z"
    }
   },
   "outputs": [],
   "source": [
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase_client: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-08T14:03:50.166709Z",
     "start_time": "2025-05-02T14:27:05.789137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n"
     ]
    }
   ],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting document with ID: 0\n",
      "Inserting document with ID: 1\n",
      "Inserting document with ID: 2\n",
      "Inserting document with ID: 3\n",
      "Inserting document with ID: 10\n",
      "Inserting document with ID: 11\n",
      "Inserting document with ID: 12\n",
      "Inserting document with ID: 13\n",
      "Inserting document with ID: 20\n",
      "Inserting document with ID: 21\n",
      "Inserting document with ID: 22\n",
      "Inserting document with ID: 23\n",
      "Inserting document with ID: 30\n",
      "Inserting document with ID: 31\n",
      "Inserting document with ID: 32\n",
      "Inserting document with ID: 33\n",
      "Inserting document with ID: 40\n",
      "Inserting document with ID: 41\n",
      "Inserting document with ID: 42\n",
      "Inserting document with ID: 43\n"
     ]
    }
   ],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve and Rerank Documents for Each Query Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the models you want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval complete for all models and queries.\n"
     ]
    }
   ],
   "source": [
    "retrieval_results = {}\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"Running retrieval with model: {model_name}\")\n",
    "    retrieval_results[model_name] = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"  Processing query: {query[:30]}...\")\n",
    "        retrieval_results[model_name][query] = retrieve(\n",
    "            query, model, supabase_client, function_name='match_documents_recency_no_filter', k=4, re_rank=True\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Completed all queries for {model_name}\")\n",
    "\n",
    "print(\"Retrieval complete for all models and queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process the Rankings\n",
    "Define 'pattern' to match the 'created' date with regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over each model and its corresponding queries\n",
    "for model, queries in retrieval_results.items():\n",
    "    for query, documents in queries.items():\n",
    "        for doc in documents:\n",
    "            created_datetime = extract_created_datetime(doc['content'], pattern=r'createdDateTime[\":]*(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z)')\n",
    "            data.append((model, query, doc['rank'], doc['id'], created_datetime))\n",
    "\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=['Model', 'Query', 'Rank', 'Document ID', 'Created DateTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the date categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date categories\n",
    "date_categories = ['newest', 'newer', 'older', 'oldest']\n",
    "\n",
    "# Sort and assign date categories within each group\n",
    "df['date_category'] = (\n",
    "    df.sort_values(by='Created DateTime', ascending=False)\n",
    "    .groupby(['Model', 'Query'])\n",
    "    .cumcount()\n",
    "    .map({i: category for i, category in enumerate(date_categories)})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Query</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Created DateTime</th>\n",
       "      <th>date_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Model, Query, Rank, Document ID, Created DateTime, date_category]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
