{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Retrieval Grammar Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.801800Z",
     "start_time": "2025-05-02T14:26:27.800913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import DATA_DIR\n",
    "from unbiasai.utils import initialize_llm, generate_embeddings, insert_documents, retrieve, get_documents_from_supabase, convert_to_doc_objects, create_reranking_prompt, perform_llm_reranking, format_results\n",
    "from supabase import create_client, Client\n",
    "from unbiasai.connection import create_supabase_client\n",
    "from dtsc_queries.retrieval_recency import test_queries\n",
    "from langchain.schema import SystemMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.812564Z",
     "start_time": "2025-05-02T14:26:28.806800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / ''\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create subset of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.819805Z",
     "start_time": "2025-05-02T14:26:28.818492Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define models and queries\n",
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Initializing model: {model_name}\")\n",
    "    \n",
    "    # Get appropriate API key for each model\n",
    "    if model_name == \"gpt\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    elif model_name == \"claude\":\n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    elif model_name == \"mistral\":\n",
    "        api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    elif model_name == \"cohere\":\n",
    "        api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    elif model_name == \"deepseek\":\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    else:\n",
    "        print(f\"Skipping unknown model: {model_name}\")\n",
    "        continue\n",
    "    \n",
    "    if not api_key:\n",
    "        print(f\"Warning: No API key found for {model_name}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Initialize and store the model\n",
    "        initialized_models[model_name] = initialize_llm(model_name, api_key)\n",
    "        print(f\"✓ Successfully initialized {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Supabase Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.828241Z",
     "start_time": "2025-05-02T14:26:28.825871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Supabase client\n",
    "SUPABASE_URL = \"https://wuxtoyrimqwohizxcmzf.supabase.co\"\n",
    "supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:27:06.549726Z",
     "start_time": "2025-05-02T14:27:05.789137Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve Documents for Each Query Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the models you want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_results = {}\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"Running retrieval with model: {model_name}\")\n",
    "    retrieval_results[model_name] = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"  Processing query: {query[:30]}...\")\n",
    "        retrieval_results[model_name][query] = retrieve(\n",
    "            query, model, supabase_client, function_name='match_documents_grammer_no_filter', k=4, re_rank=True\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Completed all queries for {model_name}\")\n",
    "\n",
    "print(\"Retrieval complete for all models and queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over each model and its corresponding queries\n",
    "for model, queries in retrieval_results.items():\n",
    "    for query, documents in queries.items():\n",
    "        for doc in documents:\n",
    "            data.append((model, query, doc['rank'], doc['id']))\n",
    "\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=['Model', 'Query', 'Rank', 'Document ID'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
