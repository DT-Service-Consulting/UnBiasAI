{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Hallucination Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T09:17:48.066635Z",
     "start_time": "2025-05-09T09:17:47.231755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unbiasai.config import DATA_DIR\n",
    "import pandas as pd\n",
    "from supabase import create_client, Client\n",
    "import os\n",
    "from unbiasai.utils import generate_embeddings\n",
    "from unbiasai.utils import initialize_llm\n",
    "from unbiasai.utils import retrieve_context\n",
    "from unbiasai.utils import run_experiment\n",
    "from unbiasai.utils import query_llm_with_rag\n",
    "from unbiasai.utils import insert_documents\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import ENVFILE\n",
    "load_dotenv(ENVFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T09:17:48.150493Z",
     "start_time": "2025-05-09T09:17:48.146271Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / 'data_raw_test.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T09:17:48.207566Z",
     "start_time": "2025-05-09T09:17:48.157394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: gpt\n",
      "    LLM initialized correctly: client=<openai.resources.chat.completions.completions.Completions object at 0x129394590> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x129395010> root_client=<openai.OpenAI object at 0x11f840590> root_async_client=<openai.AsyncOpenAI object at 0x1293946e0> model_name='gpt-4o-2024-11-20' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "Initializing model: mistral\n",
      "    LLM initialized correctly: client=<httpx.Client object at 0x129395160> async_client=<httpx.AsyncClient object at 0x1293952b0> mistral_api_key=SecretStr('**********') endpoint='https://api.mistral.ai/v1' model='mistral-small-latest' model_kwargs={}\n",
      "Initializing model: cohere\n",
      "    LLM initialized correctly: client=<cohere.client.Client object at 0x129395400> async_client=<cohere.client.AsyncClient object at 0x129395fd0> model='command-a-03-2025' cohere_api_key=SecretStr('**********')\n",
      "Initializing model: deepseek\n",
      "    LLM initialized correctly: client=<openai.resources.chat.completions.completions.Completions object at 0x1293d5590> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1293d5a90> root_client=<openai.OpenAI object at 0x1293d51d0> root_async_client=<openai.AsyncOpenAI object at 0x1293d56d0> model_name='deepseek-chat' model_kwargs={} openai_api_key=SecretStr('**********') api_key=SecretStr('**********') api_base='https://api.deepseek.com/v1'\n"
     ]
    }
   ],
   "source": [
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "models = [\"gpt\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "\n",
    "for model_name in models:\n",
    "    initialized_models[model_name] = initialize_llm(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T09:17:48.220589Z",
     "start_time": "2025-05-09T09:17:48.215161Z"
    }
   },
   "outputs": [],
   "source": [
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase_client: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T09:17:48.977475Z",
     "start_time": "2025-05-09T09:17:48.269563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n",
      "OpenAI API Key: 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\n"
     ]
    }
   ],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting document with ID: 0\n",
      "Inserting document with ID: 1\n",
      "Inserting document with ID: 2\n",
      "Inserting document with ID: 3\n",
      "Inserting document with ID: 4\n"
     ]
    }
   ],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries\n",
    "Define queries and pultiply them with desired number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]\n",
    "num_iterations = 50\n",
    "test_queries = test_queries * num_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define test query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is test query 1?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test retrieve_context function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key: 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\n",
      "Error retrieving from vector store: name 'supabase' is not defined\n",
      "Error retrieving context from knowledge base.\n"
     ]
    }
   ],
   "source": [
    "context = retrieve_context(query, top_k=4)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test query_llm_with_rag function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'claude' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = query_llm_with_rag(\u001b[43mclaude\u001b[49m, query)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[31mNameError\u001b[39m: name 'claude' is not defined"
     ]
    }
   ],
   "source": [
    "response = query_llm_with_rag(claude, query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_logs, response_df = run_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
