{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Retrieval Recency Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.801800Z",
     "start_time": "2025-05-02T14:26:27.800913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import DATA_DIR\n",
    "from unbiasai.utils import initialize_llm, generate_embeddings, insert_documents, retrieve, get_documents_from_supabase, convert_to_doc_objects, create_reranking_prompt, perform_llm_reranking, format_results, extract_created_datetime\n",
    "from supabase import create_client, Client\n",
    "from unbiasai.connection import create_supabase_client\n",
    "from dtsc_queries.retrieval_recency import test_queries\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.812564Z",
     "start_time": "2025-05-02T14:26:28.806800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / 'recency_test.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create subset of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.819805Z",
     "start_time": "2025-05-02T14:26:28.818492Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: gpt\n",
      "LLM initialized correctly: gpt, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x11cfab8c0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11cfc81a0> root_client=<openai.OpenAI object at 0x11cd5dfd0> root_async_client=<openai.AsyncOpenAI object at 0x11cfaba10> model_name='gpt-4o-2024-11-20' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized gpt\n",
      "Initializing model: claude\n",
      "LLM initialized correctly: claude, llm: model='claude-3-7-sonnet-latest' anthropic_api_url='https://api.anthropic.com' anthropic_api_key=SecretStr('**********') model_kwargs={}\n",
      "✓ Successfully initialized claude\n",
      "Initializing model: mistral\n",
      "Error initializing mistral: name 'ChatMistralAI' is not defined\n",
      "Initializing model: cohere\n",
      "LLM initialized correctly: cohere, llm: client=<cohere.client.Client object at 0x11cfc82f0> async_client=<cohere.client.AsyncClient object at 0x11cfc9010> model='command-a-03-2025' cohere_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized cohere\n",
      "Initializing model: deepseek\n",
      "LLM initialized correctly: deepseek, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x11cfe0050> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11cfec410> root_client=<openai.OpenAI object at 0x11ceabd90> root_async_client=<openai.AsyncOpenAI object at 0x11cfe0190> model_name='deepseek-chat' model_kwargs={} openai_api_key=SecretStr('**********') api_key=SecretStr('**********') api_base='https://api.deepseek.com/v1'\n",
      "✓ Successfully initialized deepseek\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define models and queries\n",
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Initializing model: {model_name}\")\n",
    "    \n",
    "    # Get appropriate API key for each model\n",
    "    if model_name == \"gpt\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    elif model_name == \"claude\":\n",
    "        api_key = os.getenv(\"CLAUDE_API_KEY\")\n",
    "    elif model_name == \"mistral\":\n",
    "        api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    elif model_name == \"cohere\":\n",
    "        api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    elif model_name == \"deepseek\":\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    else:\n",
    "        print(f\"Skipping unknown model: {model_name}\")\n",
    "        continue\n",
    "    \n",
    "    if not api_key:\n",
    "        print(f\"Warning: No API key found for {model_name}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Initialize and store the model\n",
    "        initialized_models[model_name] = initialize_llm(model_name, api_key)\n",
    "        print(f\"✓ Successfully initialized {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Supabase Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.828241Z",
     "start_time": "2025-05-02T14:26:28.825871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Supabase client\n",
    "SUPABASE_URL = \"https://wuxtoyrimqwohizxcmzf.supabase.co\"\n",
    "supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:27:06.549726Z",
     "start_time": "2025-05-02T14:27:05.789137Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting document with ID: 0\n",
      "Inserting document with ID: 1\n",
      "Inserting document with ID: 2\n",
      "Inserting document with ID: 3\n",
      "Inserting document with ID: 10\n",
      "Inserting document with ID: 11\n",
      "Inserting document with ID: 12\n",
      "Inserting document with ID: 13\n",
      "Inserting document with ID: 20\n",
      "Inserting document with ID: 21\n",
      "Inserting document with ID: 22\n",
      "Inserting document with ID: 23\n",
      "Inserting document with ID: 30\n",
      "Inserting document with ID: 31\n",
      "Inserting document with ID: 32\n",
      "Inserting document with ID: 33\n",
      "Inserting document with ID: 40\n",
      "Inserting document with ID: 41\n",
      "Inserting document with ID: 42\n",
      "Inserting document with ID: 43\n"
     ]
    }
   ],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve and Rerank Documents for Each Query Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the models you want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running retrieval with model: gpt\n",
      "  Processing query: What is test query 1?...\n",
      "  Processing query: What is test query 2?...\n",
      "  Processing query: What is test query 3?...\n",
      "✓ Completed all queries for gpt\n",
      "Running retrieval with model: claude\n",
      "  Processing query: What is test query 1?...\n",
      "Invalid ranking received: 31,33,3985,39850. Using default order.\n",
      "  Processing query: What is test query 2?...\n",
      "  Processing query: What is test query 3?...\n",
      "✓ Completed all queries for claude\n",
      "Running retrieval with model: cohere\n",
      "  Processing query: What is test query 1?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 2?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 3?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "✓ Completed all queries for cohere\n",
      "Running retrieval with model: deepseek\n",
      "  Processing query: What is test query 1?...\n",
      "Invalid ranking received: The query \"What is test query 1?\" does not have any direct relevance to the content of the provided documents. However, since Document 1 and Document 2 are identical and contain some generic terms like \"Purchases,\" \"Sales,\" etc., they might be slightly more relevant by chance compared to Documents 3 and 4, which are about quarterly performance reviews and are also identical to each other. \n",
      "\n",
      "Thus, the re-ranked order from most to least relevant is:\n",
      "1,2,3,4\n",
      "\n",
      "Final answer:\n",
      "1,2,3,4. Using default order.\n",
      "  Processing query: What is test query 2?...\n",
      "Invalid ranking received: The query is \"What is test query 2?\" and none of the documents directly address this specific query. However, we can analyze the documents for any indirect relevance or potential connections:\n",
      "\n",
      "1. Document 1 and Document 2 appear to be identical and contain accounting-related content with no relation to test queries.\n",
      "2. Document 3 discusses quarterly performance reviews, which might loosely relate to \"testing\" in an evaluation context, but not specifically to \"test query 2\".\n",
      "3. Document 4 is about shared developer environments, which might involve testing in a software development context.\n",
      "\n",
      "Given this analysis, the most relevant ordering would be:\n",
      "4,3,1,2. Using default order.\n",
      "  Processing query: What is test query 3?...\n",
      "Invalid ranking received: The query is \"What is test query 3?\" and none of the documents directly address this specific query. However, based on the content of the documents:\n",
      "\n",
      "1. Document 1 and Document 2 are identical and contain accounting-related terms but no mention of \"test query 3\".\n",
      "2. Document 3 and Document 4 are identical and discuss quarterly performance reviews, also unrelated to \"test query 3\".\n",
      "\n",
      "Since all documents are equally irrelevant to the query, the order doesn't matter, but to provide exactly 4 document numbers as requested, I'll list them in their original order:\n",
      "\n",
      "1,2,3,4. Using default order.\n",
      "✓ Completed all queries for deepseek\n",
      "Retrieval complete for all models and queries.\n"
     ]
    }
   ],
   "source": [
    "retrieval_results = {}\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"Running retrieval with model: {model_name}\")\n",
    "    retrieval_results[model_name] = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"  Processing query: {query[:30]}...\")\n",
    "        retrieval_results[model_name][query] = retrieve(\n",
    "            query, model, supabase_client, function_name='match_documents_recency_no_filter', k=4, re_rank=True\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Completed all queries for {model_name}\")\n",
    "\n",
    "print(\"Retrieval complete for all models and queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process the Rankings\n",
    "Define 'pattern' to match the 'created' date with regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over each model and its corresponding queries\n",
    "for model, queries in retrieval_results.items():\n",
    "    for query, documents in queries.items():\n",
    "        for doc in documents:\n",
    "            created_datetime = extract_created_datetime(doc['content'], pattern=r'createdDateTime[\":]*(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z)')\n",
    "            data.append((model, query, doc['rank'], doc['id'], created_datetime))\n",
    "\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=['Model', 'Query', 'Rank', 'Document ID', 'Created DateTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the date categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date categories\n",
    "date_categories = ['newest', 'newer', 'older', 'oldest']\n",
    "\n",
    "# Sort and assign date categories within each group\n",
    "df['date_category'] = (\n",
    "    df.sort_values(by='Created DateTime', ascending=False)\n",
    "    .groupby(['Model', 'Query'])\n",
    "    .cumcount()\n",
    "    .map({i: category for i, category in enumerate(date_categories)})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Query</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Document ID</th>\n",
       "      <th>Created DateTime</th>\n",
       "      <th>date_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt</td>\n",
       "      <td>What is test query 1?</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2024-06-18 15:35:22</td>\n",
       "      <td>newest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt</td>\n",
       "      <td>What is test query 1?</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2020-09-14 08:50:17</td>\n",
       "      <td>oldest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt</td>\n",
       "      <td>What is test query 1?</td>\n",
       "      <td>3</td>\n",
       "      <td>3985</td>\n",
       "      <td>2022-11-09 16:04:18</td>\n",
       "      <td>newer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt</td>\n",
       "      <td>What is test query 1?</td>\n",
       "      <td>4</td>\n",
       "      <td>39850</td>\n",
       "      <td>2022-11-09 16:04:18</td>\n",
       "      <td>older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt</td>\n",
       "      <td>What is test query 2?</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2024-06-18 15:35:22</td>\n",
       "      <td>newer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model                  Query  Rank  Document ID    Created DateTime  \\\n",
       "0   gpt  What is test query 1?     1           31 2024-06-18 15:35:22   \n",
       "1   gpt  What is test query 1?     2           33 2020-09-14 08:50:17   \n",
       "2   gpt  What is test query 1?     3         3985 2022-11-09 16:04:18   \n",
       "3   gpt  What is test query 1?     4        39850 2022-11-09 16:04:18   \n",
       "4   gpt  What is test query 2?     1           31 2024-06-18 15:35:22   \n",
       "\n",
       "  date_category  \n",
       "0        newest  \n",
       "1        oldest  \n",
       "2         newer  \n",
       "3         older  \n",
       "4         newer  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
