{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Retrieval Recency Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.801800Z",
     "start_time": "2025-05-02T14:26:27.800913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import DATA_DIR\n",
    "from unbiasai.utils import initialize_llm, generate_embeddings, insert_documents, retrieve, get_documents_from_supabase, convert_to_doc_objects, create_reranking_prompt, perform_llm_reranking, format_results\n",
    "from supabase import create_client, Client\n",
    "from unbiasai.connection import create_supabase_client\n",
    "from dtsc_queries.retrieval_recency import test_queries\n",
    "from langchain.schema import SystemMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.812564Z",
     "start_time": "2025-05-02T14:26:28.806800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / 'dataset_retrieval_recency.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create subset of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.819805Z",
     "start_time": "2025-05-02T14:26:28.818492Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: gpt\n",
      "LLM initialized correctly: gpt, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x1309a7d90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x13124bd90> root_client=<openai.OpenAI object at 0x1305ea210> root_async_client=<openai.AsyncOpenAI object at 0x131232c10> model_name='gpt-4o-2024-11-20' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized gpt\n",
      "Initializing model: claude\n",
      "Warning: No API key found for claude, skipping.\n",
      "Initializing model: mistral\n",
      "Error initializing mistral: name 'ChatMistralAI' is not defined\n",
      "Initializing model: cohere\n",
      "LLM initialized correctly: cohere, llm: client=<cohere.client.Client object at 0x130af7a10> async_client=<cohere.client.AsyncClient object at 0x131bc5940> model='command-a-03-2025' cohere_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized cohere\n",
      "Initializing model: deepseek\n",
      "LLM initialized correctly: deepseek, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x131c28e90> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x131c2b360> root_client=<openai.OpenAI object at 0x13124bb10> root_async_client=<openai.AsyncOpenAI object at 0x13124bed0> model_name='deepseek-chat' model_kwargs={} openai_api_key=SecretStr('**********') api_key=SecretStr('**********') api_base='https://api.deepseek.com/v1'\n",
      "✓ Successfully initialized deepseek\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define models and queries\n",
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Initializing model: {model_name}\")\n",
    "    \n",
    "    # Get appropriate API key for each model\n",
    "    if model_name == \"gpt\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    elif model_name == \"claude\":\n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    elif model_name == \"mistral\":\n",
    "        api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    elif model_name == \"cohere\":\n",
    "        api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    elif model_name == \"deepseek\":\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    else:\n",
    "        print(f\"Skipping unknown model: {model_name}\")\n",
    "        continue\n",
    "    \n",
    "    if not api_key:\n",
    "        print(f\"Warning: No API key found for {model_name}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Initialize and store the model\n",
    "        initialized_models[model_name] = initialize_llm(model_name, api_key)\n",
    "        print(f\"✓ Successfully initialized {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Supabase Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.828241Z",
     "start_time": "2025-05-02T14:26:28.825871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Supabase client\n",
    "SUPABASE_URL = \"https://wuxtoyrimqwohizxcmzf.supabase.co\"\n",
    "supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:27:06.549726Z",
     "start_time": "2025-05-02T14:27:05.789137Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3985\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3988\n",
      "Inserting document with ID: 3989\n"
     ]
    }
   ],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve Documents for Each Query Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the models you want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running retrieval with model: gpt\n",
      "  Processing query: What is test query 1?...\n",
      "  Processing query: What is test query 2?...\n",
      "  Processing query: What is test query 3?...\n",
      "✓ Completed all queries for gpt\n",
      "Running retrieval with model: cohere\n",
      "  Processing query: What is test query 1?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 2?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 3?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "✓ Completed all queries for cohere\n",
      "Running retrieval with model: deepseek\n",
      "  Processing query: What is test query 1?...\n",
      "Invalid ranking received: The query is \"What is test query 1?\" and none of the documents directly address this query. However, based on the content of the documents, here is the ranking from most to least relevant:\n",
      "\n",
      "1. Document 1 (ID: 39850) - Contains some generic terms but not relevant to the query.\n",
      "2. Document 2 (ID: 3985) - Same as Document 1.\n",
      "3. Document 3 (ID: 3989) - Contains detailed content about a Cafeteria Plan, which is unrelated to the query.\n",
      "4. Document 4 (ID: 3988) - Contains minimal content and is unrelated to the query.\n",
      "\n",
      "Final ranking: 1,2,3,4. Using default order.\n",
      "  Processing query: What is test query 2?...\n",
      "Invalid ranking received: The query is \"What is test query 2?\" and none of the documents directly address this query. However, we can rank them based on the likelihood of containing relevant information or being related to test queries in general.\n",
      "\n",
      "1. Document 3 (ID: 3988) - Mentions \"BRAIN\" which might be related to testing or queries.\n",
      "2. Document 4 (ID: 3987) - Contains \"Bannière\" which is less likely to be relevant but more so than accounting documents.\n",
      "3. Document 1 (ID: 39850) - Accounting content, not relevant.\n",
      "4. Document 2 (ID: 3985) - Accounting content, not relevant.\n",
      "\n",
      "Final ranking: 3,4,1,2. Using default order.\n",
      "  Processing query: What is test query 3?...\n",
      "Invalid ranking received: The query is \"What is test query 3?\" and none of the documents directly address this query. However, based on the content of the documents, here is a re-ranking from most to least relevant:\n",
      "\n",
      "1. Document 3 (ID: 3989): Although not directly relevant, it provides detailed information about a specific plan, which might be more structured and informative compared to the others.\n",
      "2. Document 4 (ID: 3988): It mentions a banner with title and author information, which might loosely relate to a \"query\" in a general sense.\n",
      "3. Document 1 (ID: 39850) and Document 2 (ID: 3985): Both documents are identical and contain accounting-related content, which is least relevant to the query.\n",
      "\n",
      "Final ranking: 3,4,1,2. Using default order.\n",
      "✓ Completed all queries for deepseek\n",
      "Retrieval complete for all models and queries.\n"
     ]
    }
   ],
   "source": [
    "retrieval_results = {}\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"Running retrieval with model: {model_name}\")\n",
    "    retrieval_results[model_name] = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"  Processing query: {query[:30]}...\")\n",
    "        retrieval_results[model_name][query] = retrieve(\n",
    "            query, model, supabase_client, k=4, re_rank=True\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Completed all queries for {model_name}\")\n",
    "\n",
    "print(\"Retrieval complete for all models and queries.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
