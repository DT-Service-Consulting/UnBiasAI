{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Retrieval Recency Bias\n",
    "\n",
    "\n",
    "\n",
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.801800Z",
     "start_time": "2025-05-02T14:26:27.800913Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from unbiasai.config import DATA_DIR\n",
    "from unbiasai.utils import initialize_llm, generate_embeddings, insert_documents, retrieve, get_documents_from_supabase, convert_to_doc_objects, create_reranking_prompt, perform_llm_reranking, format_results, extract_created_datetime\n",
    "from supabase import create_client, Client\n",
    "from unbiasai.connection import create_supabase_client\n",
    "from dtsc_queries.retrieval_recency import test_queries\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data\n",
    "Set the path and read your CSV data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.812564Z",
     "start_time": "2025-05-02T14:26:28.806800Z"
    }
   },
   "outputs": [],
   "source": [
    "file_path = DATA_DIR / 'dataset_retrieval_recency.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Create subset of data for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.819805Z",
     "start_time": "2025-05-02T14:26:28.818492Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and initialize LLMs and read your own API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model: gpt\n",
      "LLM initialized correctly: gpt, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x1131cb620> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1131d7e00> root_client=<openai.OpenAI object at 0x112f7e270> root_async_client=<openai.AsyncOpenAI object at 0x1131cb770> model_name='gpt-4o-2024-11-20' model_kwargs={} openai_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized gpt\n",
      "Initializing model: claude\n",
      "Warning: No API key found for claude, skipping.\n",
      "Initializing model: mistral\n",
      "Error initializing mistral: name 'ChatMistralAI' is not defined\n",
      "Initializing model: cohere\n",
      "LLM initialized correctly: cohere, llm: client=<cohere.client.Client object at 0x1131e8050> async_client=<cohere.client.AsyncClient object at 0x1131e8d70> model='command-a-03-2025' cohere_api_key=SecretStr('**********')\n",
      "✓ Successfully initialized cohere\n",
      "Initializing model: deepseek\n",
      "LLM initialized correctly: deepseek, llm: client=<openai.resources.chat.completions.completions.Completions object at 0x1131fc2d0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11320c690> root_client=<openai.OpenAI object at 0x1131ec050> root_async_client=<openai.AsyncOpenAI object at 0x1131fc410> model_name='deepseek-chat' model_kwargs={} openai_api_key=SecretStr('**********') api_key=SecretStr('**********') api_base='https://api.deepseek.com/v1'\n",
      "✓ Successfully initialized deepseek\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define models and queries\n",
    "models = [\"gpt\", \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
    "initialized_models = {}\n",
    "for model_name in models:\n",
    "    print(f\"Initializing model: {model_name}\")\n",
    "    \n",
    "    # Get appropriate API key for each model\n",
    "    if model_name == \"gpt\":\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    elif model_name == \"claude\":\n",
    "        api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    elif model_name == \"mistral\":\n",
    "        api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    elif model_name == \"cohere\":\n",
    "        api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "    elif model_name == \"deepseek\":\n",
    "        api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "    else:\n",
    "        print(f\"Skipping unknown model: {model_name}\")\n",
    "        continue\n",
    "    \n",
    "    if not api_key:\n",
    "        print(f\"Warning: No API key found for {model_name}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Initialize and store the model\n",
    "        initialized_models[model_name] = initialize_llm(model_name, api_key)\n",
    "        print(f\"✓ Successfully initialized {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Supabase Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "SUPABASE_KEY = os.getenv(\"SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connect to Supabase and create a Vector Store\n",
    "Connect to Supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:26:28.828241Z",
     "start_time": "2025-05-02T14:26:28.825871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Supabase client\n",
    "SUPABASE_URL = \"https://wuxtoyrimqwohizxcmzf.supabase.co\"\n",
    "supabase_client = create_client(SUPABASE_URL, SUPABASE_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the generate_embedding function to your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-02T14:27:06.549726Z",
     "start_time": "2025-05-02T14:27:05.789137Z"
    }
   },
   "outputs": [],
   "source": [
    "df['embedding'] = df['content'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert your new df including the embeddings in the supabase table to create a vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3984\n",
      "Inserting document with ID: 3985\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3986\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3987\n",
      "Inserting document with ID: 3988\n",
      "Inserting document with ID: 3989\n"
     ]
    }
   ],
   "source": [
    "insert_documents(df, supabase_client)\n",
    "# IMPORTANT: change function so supabase table name can be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define your Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What is test query 1?\",\n",
    "    \"What is test query 2?\",\n",
    "    \"What is test query 3?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Retrieve and Rerank Documents for Each Query Across All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the models you want to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running retrieval with model: gpt\n",
      "  Processing query: What is test query 1?...\n",
      "  Processing query: What is test query 2?...\n",
      "  Processing query: What is test query 3?...\n",
      "✓ Completed all queries for gpt\n",
      "Running retrieval with model: cohere\n",
      "  Processing query: What is test query 1?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 2?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "  Processing query: What is test query 3?...\n",
      "Re-ranking failed: status_code: 402, body: {'message': 'Please add or update your payment method at https://dashboard.cohere.com/billing?tab=payment to continue'}. Using initial ranking.\n",
      "✓ Completed all queries for cohere\n",
      "Running retrieval with model: deepseek\n",
      "  Processing query: What is test query 1?...\n",
      "Invalid ranking received: The query \"What is test query 1?\" is very general and does not provide specific context. Given the content of the documents, none of them directly address the query. However, based on the content, here is a ranking from most to least relevant:\n",
      "\n",
      "1. Document 3 (ID: 3989): Although not directly relevant, it provides detailed information about a specific topic (Cafeteria Plan), which might be more useful than the other documents.\n",
      "2. Document 4 (ID: 3988): It mentions a banner with title and author information, which is somewhat related to general queries but still not directly relevant.\n",
      "3. Document 1 (ID: 3985) and Document 2 (ID: 39850): Both documents are identical and contain accounting-related content, which is least relevant to the query.\n",
      "\n",
      "Since Document 1 and Document 2 are identical, their order does not matter. \n",
      "\n",
      "Final ranking: 3,4,1,2. Using default order.\n",
      "  Processing query: What is test query 2?...\n",
      "Invalid ranking received: The query is \"What is test query 2?\" and none of the documents directly address this query. However, we can rank them based on potential indirect relevance or content similarity.\n",
      "\n",
      "1. Document 3 (ID: 3988) - Contains the word \"BRAIN\" which might be loosely related to a \"test query\" in a conceptual sense.\n",
      "2. Document 4 (ID: 3987) - Contains banners and dates, which might be loosely related to testing or queries.\n",
      "3. Document 1 (ID: 3985) - Accounting content, least relevant.\n",
      "4. Document 2 (ID: 39850) - Appears to be identical to Document 1, making it equally irrelevant.\n",
      "\n",
      "Final ranking: 3,4,1,2. Using default order.\n",
      "  Processing query: What is test query 3?...\n",
      "Invalid ranking received: The query is \"What is test query 3?\" and none of the documents directly address this specific query. However, based on the content of the documents:\n",
      "\n",
      "1. Document 3 (ID: 3989) - Although not directly relevant, it provides detailed information about a Cafeteria Plan, which is more substantive than the other documents.\n",
      "2. Document 4 (ID: 3988) - Contains minimal content about a banner titled \"BRAIN,\" which is slightly more informative than Documents 1 and 2.\n",
      "3. Document 1 (ID: 3985) - Contains generic accounting terms but no relevant information to the query.\n",
      "4. Document 2 (ID: 39850) - Appears to be a duplicate of Document 1, with the same content.\n",
      "\n",
      "Final ranking: 3,4,1,2. Using default order.\n",
      "✓ Completed all queries for deepseek\n",
      "Retrieval complete for all models and queries.\n"
     ]
    }
   ],
   "source": [
    "retrieval_results = {}\n",
    "for model_name, model in initialized_models.items():\n",
    "    print(f\"Running retrieval with model: {model_name}\")\n",
    "    retrieval_results[model_name] = {}\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"  Processing query: {query[:30]}...\")\n",
    "        retrieval_results[model_name][query] = retrieve(\n",
    "            query, model, supabase_client, function_name='match_documents_recency_no_filter', k=4, re_rank=True\n",
    "        )\n",
    "    \n",
    "    print(f\"✓ Completed all queries for {model_name}\")\n",
    "\n",
    "print(\"Retrieval complete for all models and queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Process the Rankings\n",
    "Define 'pattern' to match the 'created' date with regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to collect data\n",
    "data = []\n",
    "\n",
    "# Iterate over each model and its corresponding queries\n",
    "for model, queries in retrieval_results.items():\n",
    "    for query, documents in queries.items():\n",
    "        for doc in documents:\n",
    "            created_datetime = extract_created_datetime(doc['content'], pattern=r'createdDateTime[\":]*(\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}(?:\\.\\d+)?Z)')\n",
    "            data.append((model, query, doc['rank'], doc['id'], created_datetime))\n",
    "\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(data, columns=['Model', 'Query', 'Rank', 'Document ID', 'Created DateTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the date categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date categories\n",
    "date_categories = ['newest', 'newer', 'older', 'oldest']\n",
    "\n",
    "# Sort and assign date categories within each group\n",
    "df['date_category'] = (\n",
    "    df.sort_values(by='Created DateTime', ascending=False)\n",
    "    .groupby(['Model', 'Query'])\n",
    "    .cumcount()\n",
    "    .map({i: category for i, category in enumerate(date_categories)})\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
