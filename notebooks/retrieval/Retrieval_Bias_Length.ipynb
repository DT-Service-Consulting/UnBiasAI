{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#run\n",
        "!pip install --quiet langchain langchain-anthropic langchain-community faiss-cpu pypdf python-dotenv langchain_mistralai langchain_deepseek langchain_cohere asyncio psutil GPUtil supabase"
      ],
      "metadata": {
        "id": "E_jBLsrJsnLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f8e8e9-a57c-44c0-b8b8-497710dc3999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rfKF0vRlacvG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pmhXd8Dq6Aa"
      },
      "outputs": [],
      "source": [
        "#run\n",
        "#Importing the packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "from math import log\n",
        "from collections import Counter\n",
        "import itertools\n",
        "import re\n",
        "import supabase\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import SupabaseVectorStore\n",
        "from langchain_openai import OpenAIEmbeddings  # New package as per deprecation warning\n",
        "from langchain.vectorstores import SupabaseVectorStore\n",
        "from langchain.chat_models import ChatOpenAI  # For GPT-4 and as a placeholder for Mistral\n",
        "from langchain.chat_models import ChatAnthropic  # For Claude (ensure compatibility with your LangChain version)\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "import re\n",
        "from datetime import datetime\n",
        "from supabase import create_client, Client\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain_cohere import ChatCohere\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 1. Read CSV Data\n",
        "# -------------------------------\n",
        "from google.colab import drive # VH\n",
        "drive.mount('/content/drive') # VH\n",
        "file_path = \"/content/drive/My Drive/Internship DTSC/Dataset Length Bias 0407.csv\" # VH\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"CSV loaded with {} records.\".format(len(df)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QoRrjBfrY6U",
        "outputId": "c5d9d3b0-c667-4654-97c9-8d6c53547421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "CSV loaded with 147 records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##run\n",
        "#REading the API key\n",
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('OpenAI')\n",
        "supabase_key = userdata.get('Supabase_key') #vector store\n",
        "MISTRAL_API_KEY = userdata.get('Mistral')\n",
        "CLAUDE_API_KEY = userdata.get('Anthropic')\n",
        "COHERE_API_KEY = userdata.get('Cohere')\n",
        "DEEPSEEK_API_KEY = userdata.get('Deepseek')\n",
        "# GEMINI_API_KEY = userdata.get('Gemini')\n"
      ],
      "metadata": {
        "id": "UwbVvgkWxd2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# 2. Connect to Supabase and Create a Vector Store\n",
        "# -------------------------------\n",
        "# Note: Install the required supabase and langchain libraries.\n",
        "# Replace with your actual credentials.\n",
        "\n",
        "SUPABASE_URL = \"\"\n",
        "SUPABASE_KEY = supabase_key\n",
        "# OPENAI_API_KEY = openai_key # VH delete?\n",
        "\n",
        "supabase_client = supabase.create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "# Initialize your embeddings using the new import:\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "# Define the table name where your documents will be stored.\n",
        "table_name = \"retrieval_length\"\n",
        "# Create the Supabase vector store by providing the client, embeddings, and table_name.\n",
        "vector_store = SupabaseVectorStore(client=supabase_client, embedding=embeddings, table_name=table_name)"
      ],
      "metadata": {
        "id": "c30lSFo0rfmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embedding(text):\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY,model=\"text-embedding-3-large\")  # Use the appropriate model\n",
        "    response = embeddings.embed_query(text)  # Correctly call the method to generate embeddings\n",
        "    embedding = response\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "g9f74irhBZe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VH Gives error because of unexpected float values in content\n",
        "# Generate embeddings for each row\n",
        "df['embedding'] = df['content'].apply(generate_embedding) # do not run too much!"
      ],
      "metadata": {
        "id": "gFhelPT45Ft0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_MY4Rtbb5FqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_documents(df: pd.DataFrame):\n",
        "    for index, row in df.iterrows():\n",
        "        print(f\"Inserting document with ID: {int(row['id'])}\") # VH Previously: print(f\"Inserting document with ID: {int(row['id']*10)}\")\n",
        "        data = {\n",
        "            \"id\": int(row[\"id\"]*10), # VH Previously: \"id\": int(row[\"id\"]*10),\n",
        "            \"content\": row[\"content\"],\n",
        "            \"metadata\": row.get(\"metadata\", None),\n",
        "            \"embedding\": row[\"embedding\"]\n",
        "        }\n",
        "        response = supabase_client.table(\"retrieval_length\").upsert(data).execute() # VH table name should correspond exactly with given name in supabase / upsert instead of insert\n",
        "\n"
      ],
      "metadata": {
        "id": "iJy4cwztrhZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_documents(df)"
      ],
      "metadata": {
        "id": "QP_VnQToLSEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text):\n",
        "    \"\"\"Get embeddings for a text using OpenAI's embedding model\"\"\"\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY,model=\"text-embedding-3-large\")  # Use the appropriate model\n",
        "    response = embeddings.embed_query(text)  # Correctly call the method to generate embeddings\n",
        "    embedding = response\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "--b6sFCdu5w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Connect to Supabase\n",
        " ### Supabase Credentials\n",
        "SUPABASE_URL = \"\"\n",
        "SUPABASE_KEY = supabase_key\n",
        "\n",
        "\n",
        "# Create Supabase client\n",
        "supabase = create_client(SUPABASE_URL, SUPABASE_KEY)"
      ],
      "metadata": {
        "id": "Chk6JEz5u5tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 3. Define Retrieval Function for Multiple Models with Re-Ranking\n",
        "# -------------------------------\n",
        "\n",
        "def retrieve(query, model_name, k=10, re_rank=False):\n",
        "    \"\"\"\n",
        "    Retrieve top-k documents for a query using Supabase vector search with optional LLM re-ranking.\n",
        "\n",
        "    Parameters:\n",
        "      query (str): The search query.\n",
        "      model_name (str): One of 'gpt-4o-mini', 'claude', 'mistral', etc.\n",
        "      k (int): Number of top documents to retrieve.\n",
        "      re_rank (bool): Whether to re-rank the documents using the LLM.\n",
        "\n",
        "    Returns:\n",
        "      List[dict]: A list of dictionaries with document 'id', 'rank', and 'content'.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize LLM\n",
        "    model_name = model_name.lower()\n",
        "    if model_name == \"gpt\":\n",
        "        llm = ChatOpenAI(model_name=\"gpt-4o-2024-11-20\", openai_api_key=OPENAI_API_KEY)\n",
        "    elif model_name == \"claude\":\n",
        "        llm = ChatAnthropic(model=\"claude-3-7-sonnet-latest\", anthropic_api_key=CLAUDE_API_KEY)\n",
        "    elif model_name == \"mistral\":\n",
        "        llm = ChatMistralAI(model=\"mistral-large-latest\", mistral_api_key=MISTRAL_API_KEY)\n",
        "    elif model_name == \"cohere\":\n",
        "        llm = ChatCohere(model=\"command-a-03-2025\", cohere_api_key=COHERE_API_KEY)\n",
        "    elif model_name == \"deepseek\":\n",
        "        import os\n",
        "        os.environ[\"DEEPSEEK_API_KEY\"] = DEEPSEEK_API_KEY\n",
        "        llm = ChatDeepSeek(model=\"deepseek-v3-chat\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "    try:\n",
        "        # Step 1: Get embedding\n",
        "        query_embedding = get_embedding(query)\n",
        "\n",
        "        # Step 2: Retrieve documents from Supabase via RPC\n",
        "        response = supabase.rpc(\n",
        "            'match_documents_length_no_filter',\n",
        "            {\n",
        "                'query_embedding': query_embedding,\n",
        "                'match_count': k\n",
        "            }\n",
        "        ).execute()\n",
        "\n",
        "        if not response.data or len(response.data) == 0:\n",
        "            print(\"No relevant documents found.\")\n",
        "            return []\n",
        "\n",
        "        # Step 3: Build document list\n",
        "        docs = [\n",
        "            type(\"Doc\", (object,), {\n",
        "                \"id\": doc.get(\"id\"),\n",
        "                \"page_content\": doc.get(\"content\", \"\"),\n",
        "                \"metadata\": doc.get(\"metadata\", {})\n",
        "            })()\n",
        "            for doc in response.data\n",
        "        ]\n",
        "\n",
        "        actual_k = min(k, len(docs))\n",
        "\n",
        "        # Step 4: Optional re-ranking\n",
        "        if re_rank and actual_k > 1:\n",
        "            try:\n",
        "                documents_text = \"\\n\\n\".join([\n",
        "                    f\"Document {i+1} (ID: {docs[i].id}):\\n{docs[i].page_content}\"\n",
        "                    for i in range(actual_k)\n",
        "                ])\n",
        "\n",
        "                prompt = f\"\"\"\n",
        "                Query: {query}\n",
        "\n",
        "                You will be given {actual_k} documents retrieved via semantic search.\n",
        "                Your task is to re-rank these documents in order of their relevance to the query.\n",
        "                Please return EXACTLY {actual_k} document numbers in order, from MOST to LEAST relevant,\n",
        "                separated by commas (e.g., \"3,1,2\").\n",
        "\n",
        "                Documents:\n",
        "                {documents_text}\n",
        "                \"\"\"\n",
        "\n",
        "                messages = [\n",
        "                    SystemMessage(content=\"You are a helpful assistant skilled at ranking document relevance.\"),\n",
        "                    HumanMessage(content=prompt)\n",
        "                ]\n",
        "\n",
        "                llm_response = llm.invoke(messages)\n",
        "                ranking_text = llm_response.content.strip()\n",
        "                ranking_order = [int(num.strip()) - 1 for num in re.findall(r'\\d+', ranking_text)]\n",
        "\n",
        "                if len(ranking_order) != actual_k or sorted(ranking_order) != list(range(actual_k)):\n",
        "                    print(f\"Invalid ranking received: {ranking_text}. Using default order.\")\n",
        "                    ranking_order = list(range(actual_k))\n",
        "\n",
        "                docs = [docs[i] for i in ranking_order]\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Re-ranking failed: {e}. Using initial ranking.\")\n",
        "\n",
        "        # Step 5: Return formatted result\n",
        "        results = [\n",
        "            {\n",
        "                \"id\": doc.id,\n",
        "                \"rank\": idx + 1,\n",
        "                \"content\": doc.page_content\n",
        "            }\n",
        "            for idx, doc in enumerate(docs)\n",
        "        ]\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving documents: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "BrmYY5Ynw2lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Aor8Tk1lroWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VH For display in next cell\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "3xu78M2UJbtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage (uncomment to test):\n",
        "results_example = retrieve(\"How do I connect to Outlook?\", \"gpt\", k=3, re_rank=True)\n",
        "print(results_example)\n",
        "#display(HTML(f\"<pre style='white-space:pre-wrap;'>{results_example}</pre>\")) # VH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX_cpgxfruqz",
        "outputId": "557ecbde-437c-4b30-bed8-f6db6f1c13b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-e80e3714b995>:22: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4o-2024-11-20\", openai_api_key=OPENAI_API_KEY)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'id': 398620, 'rank': 1, 'content': 'output.id: 368d3765-a38d-4f63-bffe-0f59d86be5dc | output.metadata: webUrl\":\"https://dtservicesandconsulting.sharepoint.com/sites/DTServicesandConsultingSRL/SitePages/Associer-ton-calendrier-Officient-%C3%A0-Outlook-(cong%C3%A9s-des-coll%C3%A8gues).aspx, who created it: \"displayName\":\"Samuel  Aulotte\",\"email\":\"samuel.aulotte@dtsc.be\" and when it was created: \"createdDateTime\":\"2025-02-25T13:27:58Z\" and last time it was modified: \"lastModifiedDateTime\":\"2025-02-28T10:00:35Z\" | output.content:\\n\\n1. Access Calendar Settings\\n- Open your calendar in Officient.\\n- Click on the gear icon to access the settings.\\n\\n2. Link Your Personal Calendar\\n- Select the option \"Link your personal calendar.\"\\n- A list of links will be provided for different calendar integrations.\\n- Find and copy the link corresponding to your personal calendar.\\n- Make sure to keep this link private as it contains access to your calendar data.\\n\\n3. Add Your Calendar to Outlook\\n- Open Outlook in your web browser or desktop application.\\n- In the left navigation column, select \"Calendar.\"\\n- Look for and click on the \"Add a calendar\" option in the menu.\\n- On the page that opens, select \"Subscribe from the web\" from the available options.\\n- Paste the previously copied link from Officient into the designated field.\\n- Choose whether to create a new separate calendar or merge the information with an existing calendar.\\n- You can also customize the name and color of this calendar for better organization.\\n- Set refresh frequency if the option is available.\\n\\nAnd that\\'s it! Your Officient calendar is now synced with Outlook! Any leaves or absences from colleagues will now appear in your Outlook calendar, helping you better plan your work and meetings. üéâ\\n\\nNote: The calendar sync is one-way from Officient to Outlook. Changes made in Outlook will not be reflected in Officient.'}, {'id': 398600, 'rank': 2, 'content': 'output.id: 368d3765-a38d-4f63-bffe-0f59d86be5dc | output.metadata: webUrl\":\"https://dtservicesandconsulting.sharepoint.com/sites/DTServicesandConsultingSRL/SitePages/Associer-ton-calendrier-Officient-%C3%A0-Outlook-(cong%C3%A9s-des-coll%C3%A8gues).aspx, who created it: \"displayName\":\"Samuel  Aulotte\",\"email\":\"samuel.aulotte@dtsc.be\" and when it was created: \"createdDateTime\":\"2025-02-25T13:27:58Z\" and last time it was modified: \"lastModifiedDateTime\":\"2025-02-28T10:00:35Z\" | output.content: 1. Access Calendar Settings\\n‚Ä¢ Open your calendar in Officient.\\n‚Ä¢ Click on the gear icon to access the settings.\\n\\n2. Link Your Personal Calendar\\n‚Ä¢ Select the option \"Link your personal calendar.\"\\n‚Ä¢ A list of links will be provided.\\n‚Ä¢ Copy the link corresponding to your calendar.\\n\\n3. Add Your Calendar to Outlook\\n‚Ä¢ Open Outlook.\\n‚Ä¢ In the left column, select \"Calendar.\"\\n\\n‚Ä¢ Click on \"Add a calendar.\"\\n\\n‚Ä¢ On the page that opens, select \"Subscribe from the web.\"\\n\\n‚Ä¢ Paste the previously copied link.\\n\\n‚Ä¢ Choose whether to create a new calendar or merge the information with an existing calendar.\\n\\nAnd that‚Äôs it! Your Officient calendar is now synced with Outlook! üéâ'}, {'id': 398610, 'rank': 3, 'content': 'output.id: 368d3765-a38d-4f63-bffe-0f59d86be5dc | output.metadata: webUrl\":\"https://dtservicesandconsulting.sharepoint.com/sites/DTServicesandConsultingSRL/SitePages/Associer-ton-calendrier-Officient-%C3%A0-Outlook-(cong%C3%A9s-des-coll%C3%A8gues).aspx, who created it: \"displayName\":\"Samuel  Aulotte\",\"email\":\"samuel.aulotte@dtsc.be\" and when it was created: \"createdDateTime\":\"2025-02-25T13:27:58Z\" and last time it was modified: \"lastModifiedDateTime\":\"2025-02-28T10:00:35Z\" | output.content:\\n\\n1. Access Calendar Settings\\n- Open your calendar in Officient.\\n- Click on the gear icon to access the settings.\\n\\n2. Link Your Personal Calendar\\n- Select \"Link your personal calendar.\"\\n- A list of links will appear.\\n- Copy the link for your calendar.\\n\\n3. Add Your Calendar to Outlook\\n- Open Outlook.\\n- Select \"Calendar\" in the left column.\\n- Click on \"Add a calendar.\"\\n- Select \"Subscribe from the web.\"\\n- Paste the previously copied link.\\n- Choose to create a new calendar or merge with existing one.\\n\\nYour Officient calendar is now synced with Outlook! üéâ'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 4. Prepare 50 Test Queries        VH: it's 49 now\n",
        "# -------------------------------\n",
        "test_queries = [\n",
        "    \"Bo√Æte aux lettres?\", # 3985\n",
        "    \"How can I access my Officient Calendar?\", # 3986\n",
        "    \"Banni√®re?\", # 3987\n",
        "    \"What are the cafeteria plan benefits?\", # 3989\n",
        "    \"What about my car configuration offer?\", # 3990\n",
        "    \"How do I create a Canva?\", # 3991\n",
        "    \"What about chargemap business?\", # 3992\n",
        "    \"What is the Moodboard?\", # 3993\n",
        "    \"What about Chargemap (domicile)?\", # 3994\n",
        "    \"What about Connecting Expertise?\", # 3995\n",
        "    \"What's the BeCentral address?\", # 3996\n",
        "    \"What about a Microsoft 365 license?\", # 3997\n",
        "    \"What about Google Calendar\", # 3998\n",
        "    \"What is Call to Action?\", # 3999\n",
        "    \"What are compensatory rest days?\", # 4000\n",
        "    \"How do I access the shared library?\", # 4001\n",
        "    \"What is the login for StaffIT?\", # 4003\n",
        "    \"How to Backup Odoo Contacts?\", # 4005\n",
        "    \"How can I export leads from Odoo?\", # 4006\n",
        "    \"What is Lean six sigma?\", # 4007\n",
        "    \"What is the fleet policy for traffic fines?\", # 4008\n",
        "    \"What about dtsc.be performance?\", # 4010\n",
        "    \"What is a collaborative mailbox?\", # 4011\n",
        "    \"What about a green card?\", # 4014\n",
        "    \"Where about Securex?\", # 4015\n",
        "    \"How to create a teams meeting from Google Agenda?\", # 4017\n",
        "    \"What about Supplementary Family Allowances?\", # 4018\n",
        "    \"Core rules Posts?\", # 4019\n",
        "    \"What activities are included in the DTeam Spirit Challenge?\", # 4020\n",
        "    \"What are the limits for the mobility budget?\", # 4021\n",
        "    \"What about Nexxtmove?\", # 4024\n",
        "    \"Enable Mail Plugin?\", # 4025\n",
        "    \"What about Officient employee self-service?\", # 4026\n",
        "    \"What about ECO vouchers?\", # 4027\n",
        "    \"What about birth leave?\", # 4028\n",
        "    \"What about dtsc.odoo.com?\", # 4030\n",
        "    \"What about ProUnity?\", # 4031\n",
        "    \"What about a hiring bonus?\", # 4032\n",
        "    \"What about Powerdale?\", # 4034\n",
        "    \"What about Single Permits?\", # 4036\n",
        "    \"What about dbudin@dtsc.be.tapfin?\", # 4037\n",
        "    \"What about Elia Recent Job Requisitions?\", # 4038\n",
        "    \"What about Subsidies?\", # 4040\n",
        "    \"Who are our suppliers?\", # 4041\n",
        "    \"What is TED?\", # 4042\n",
        "    \"How to activate Music Streaming?\", # 4043\n",
        "    \"What are PYXIS and Scrum?\", # 4046\n",
        "    \"How to open another mailbox?\", # 4047\n",
        "    \"What about BNP Paribas warrants?\" # 4048\n",
        "]"
      ],
      "metadata": {
        "id": "4N82AFgjr2N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VH retrieval test\n",
        "def process_multiple_questions(questions_list, model=\"gpt-4o-mini\", k=3, re_rank=True, search_method=\"keyword\"):\n",
        "    \"\"\"\n",
        "    Process multiple questions through the retrieve function and display results\n",
        "\n",
        "    Args:\n",
        "        questions_list: List of question strings\n",
        "        model: Model to use for retrieval\n",
        "        k: Number of results to return\n",
        "        re_rank: Whether to re-rank results\n",
        "        search_method: Method for search (\"keyword\" or other options)\n",
        "    \"\"\"\n",
        "    from IPython.display import HTML, display\n",
        "\n",
        "    for question in questions_list:\n",
        "        print(f\"\\nProcessing question: {question}\")\n",
        "        results = retrieve(question, model, k=k, re_rank=re_rank, search_method=search_method)\n",
        "\n",
        "        # Handle results based on its type\n",
        "        if isinstance(results, list):\n",
        "            # If results is a list, join the items with double newlines\n",
        "            formatted_results = \"\\n\\n\".join([str(item) for item in results])\n",
        "        else:\n",
        "            # If results is a string, add line breaks\n",
        "            if k > 1:\n",
        "                formatted_results = results.replace(\"\\n\", \"\\n\\n\")\n",
        "            else:\n",
        "                formatted_results = results\n",
        "\n",
        "        display(HTML(f\"<pre style='white-space:pre-wrap;'>{formatted_results}</pre>\"))\n",
        "        print(\"-\" * 80)  # Separator between questions\n",
        "\n",
        "# Example usage with your questions list:\n",
        "questions = [\n",
        "    \"Bo√Æte aux lettres?\", # 3985\n",
        "    \"How can I access my Officient Calendar?\", # 3986\n",
        "    \"Banni√®re?\", # 3987\n",
        "    \"What are the cafeteria plan benefits?\", # 3989\n",
        "    \"What about my car configuration offer?\", # 3990\n",
        "    \"How do I create a Canva?\", # 3991\n",
        "    \"What about chargemap business?\", # 3992\n",
        "    \"What is the Moodboard?\", # 3993\n",
        "    \"What about Chargemap (domicile)?\", # 3994\n",
        "    \"What about Connecting Expertise?\", # 3995\n",
        "    \"What's the BeCentral address?\", # 3996\n",
        "    \"What about a Microsoft 365 license?\", # 3997\n",
        "    \"What about Google Calendar\", # 3998\n",
        "    \"What is Call to Action?\", # 3999\n",
        "    \"What are compensatory rest days?\", # 4000\n",
        "    \"How do I access the shared library?\", # 4001\n",
        "    \"What is the login for StaffIT?\", # 4003\n",
        "    \"How to Backup Odoo Contacts?\", # 4005\n",
        "    \"How can I export leads from Odoo?\", # 4006\n",
        "    \"What is Lean six sigma?\", # 4007\n",
        "    \"What is the fleet policy for traffic fines?\", # 4008\n",
        "    \"What about dtsc.be performance?\", # 4010\n",
        "    \"What is a collaborative mailbox?\", # 4011\n",
        "    \"What about a green card?\", # 4014\n",
        "    \"Where about Securex?\", # 4015\n",
        "    \"How to create a teams meeting from Google Agenda?\", # 4017\n",
        "    \"What about Supplementary Family Allowances?\", # 4018\n",
        "    \"Core rules Posts?\", # 4019\n",
        "    \"What activities are included in the DTeam Spirit Challenge?\", # 4020\n",
        "    \"What are the limits for the mobility budget?\", # 4021\n",
        "    \"What about Nexxtmove?\", # 4024\n",
        "    \"Enable Mail Plugin?\", # 4025\n",
        "    \"What about Officient employee self-service?\", # 4026\n",
        "    \"What about ECO vouchers?\", # 4027\n",
        "    \"What about birth leave?\", # 4028\n",
        "    \"What about dtsc.odoo.com?\", # 4030\n",
        "    \"What about ProUnity?\", # 4031\n",
        "    \"What about a hiring bonus?\", # 4032\n",
        "    \"What about Powerdale?\", # 4034\n",
        "    \"What about Single Permits?\", # 4036\n",
        "    \"What about dbudin@dtsc.be.tapfin?\", # 4037\n",
        "    \"What about Elia Recent Job Requisitions?\", # 4038\n",
        "    \"What about Subsidies?\", # 4040\n",
        "    \"Who are our suppliers?\", # 4041\n",
        "    \"What is TED?\", # 4042\n",
        "    \"How to activate Music Streaming?\", # 4043\n",
        "    \"What are PYXIS and Scrum?\", # 4046\n",
        "    \"How to open another mailbox?\", # 4047\n",
        "    \"What about BNP Paribas warrants?\" # 4048\n",
        "]\n",
        "\n",
        "# Uncomment to run:\n",
        "# process_multiple_questions(questions, \"gpt-4o-mini\", k=3, re_rank=True, search_method=\"keyword\")"
      ],
      "metadata": {
        "id": "sx6o1jWn8Rsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure exactly 50 queries.    VH: it's 49\n",
        "if len(test_queries) < 49:\n",
        "    test_queries = test_queries * (49 // len(test_queries) + 1)\n",
        "test_queries = test_queries[:49]\n",
        "print(\"Prepared {} test queries.\".format(len(test_queries)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "salkA1XVr9cz",
        "outputId": "e0737624-667a-40e5-880b-ef950a389165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prepared 49 test queries.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_queries"
      ],
      "metadata": {
        "id": "gvUNZ5YGcum8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# 5. Retrieve Documents for Each Query Across All Models\n",
        "# -------------------------------\n",
        "# Initialize a list to collect data\n",
        "\n",
        "models = [\"gpt-4o-mini\",  \"claude\", \"mistral\", \"cohere\", \"deepseek\"]\n",
        "# retrieval_results structure: { model_name: { query: [list of document results] } }\n",
        "retrieval_results = {model: {} for model in models}\n",
        "\n",
        "for model in models:\n",
        "    for query in test_queries:\n",
        "        # Set re_rank=True if you wish to re-rank documents using the LLM.\n",
        "        retrieval_results[model][query] = retrieve(query, model, k=3, re_rank=True, search_method=\"keyword\")\n",
        "print(\"Retrieval complete for all models and queries.\")"
      ],
      "metadata": {
        "id": "lDYfrty-sBGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_content_word_count(df):\n",
        "    \"\"\"\n",
        "    Analyzes content column and counts words after \"output.content: \"\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): DataFrame with a 'content' column\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: DataFrame with 'word_count' column added\n",
        "    \"\"\"\n",
        "    # Create a copy of the dataframe\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # Count words after marker\n",
        "    def count_words(text):\n",
        "        if not isinstance(text, str):\n",
        "            return 0\n",
        "\n",
        "        marker = \"output.content: \"\n",
        "        pos = text.find(marker)\n",
        "\n",
        "        if pos == -1:\n",
        "            return len(text.split())  # Count all words if marker not found\n",
        "\n",
        "        # Extract content after marker and count words\n",
        "        content_after_marker = text[pos + len(marker):]\n",
        "        return len(content_after_marker.split())\n",
        "\n",
        "    # Apply word counting\n",
        "    result_df['word_count'] = result_df['content'].apply(count_words)\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "781SlTqqN-fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VH Apply word count function and create df\n",
        "\n",
        "# Initialize a list to collect data\n",
        "data = []\n",
        "\n",
        "# Iterate over each model and its corresponding queries\n",
        "for model, queries in retrieval_results.items():\n",
        "    for query, documents in queries.items():\n",
        "        for doc in documents:\n",
        "            data.append((model, query, doc['rank'], doc['id'], doc['content']))\n",
        "\n",
        "# Create a DataFrame from the collected data\n",
        "df = pd.DataFrame(data, columns=['Model', 'Query', 'Rank', 'Document ID', 'content'])\n",
        "\n",
        "# Apply the analyze_content_word_count function to add word count and categories\n",
        "df = analyze_content_word_count(df)\n",
        "df = df.drop(columns=['content'])"
      ],
      "metadata": {
        "id": "XZhpFZo5LIS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "gcHogUjHT155",
        "outputId": "db4bb774-cc3e-4971-9596-e2c30fbcc3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Model                                    Query  Rank  Document ID  \\\n",
              "0    gpt-4o-mini                       Bo√Æte aux lettres?     1       398420   \n",
              "1    gpt-4o-mini                       Bo√Æte aux lettres?     2       398400   \n",
              "2    gpt-4o-mini                       Bo√Æte aux lettres?     3       398410   \n",
              "3    gpt-4o-mini  How can I access my Officient Calendar?     1       398600   \n",
              "4    gpt-4o-mini  How can I access my Officient Calendar?     2       398620   \n",
              "..           ...                                      ...   ...          ...   \n",
              "725     deepseek             How to open another mailbox?     2       404710   \n",
              "726     deepseek             How to open another mailbox?     3       404720   \n",
              "727     deepseek         What about BNP Paribas warrants?     1       404800   \n",
              "728     deepseek         What about BNP Paribas warrants?     2       404810   \n",
              "729     deepseek         What about BNP Paribas warrants?     3       404820   \n",
              "\n",
              "     word_count  \n",
              "0           706  \n",
              "1           142  \n",
              "2           104  \n",
              "3           116  \n",
              "4           256  \n",
              "..          ...  \n",
              "725         196  \n",
              "726         649  \n",
              "727          46  \n",
              "728         168  \n",
              "729         546  \n",
              "\n",
              "[730 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fbf8bb0-6d81-4be9-833c-2079397198fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Query</th>\n",
              "      <th>Rank</th>\n",
              "      <th>Document ID</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>Bo√Æte aux lettres?</td>\n",
              "      <td>1</td>\n",
              "      <td>398420</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>Bo√Æte aux lettres?</td>\n",
              "      <td>2</td>\n",
              "      <td>398400</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>Bo√Æte aux lettres?</td>\n",
              "      <td>3</td>\n",
              "      <td>398410</td>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>How can I access my Officient Calendar?</td>\n",
              "      <td>1</td>\n",
              "      <td>398600</td>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gpt-4o-mini</td>\n",
              "      <td>How can I access my Officient Calendar?</td>\n",
              "      <td>2</td>\n",
              "      <td>398620</td>\n",
              "      <td>256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>725</th>\n",
              "      <td>deepseek</td>\n",
              "      <td>How to open another mailbox?</td>\n",
              "      <td>2</td>\n",
              "      <td>404710</td>\n",
              "      <td>196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>726</th>\n",
              "      <td>deepseek</td>\n",
              "      <td>How to open another mailbox?</td>\n",
              "      <td>3</td>\n",
              "      <td>404720</td>\n",
              "      <td>649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>deepseek</td>\n",
              "      <td>What about BNP Paribas warrants?</td>\n",
              "      <td>1</td>\n",
              "      <td>404800</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>deepseek</td>\n",
              "      <td>What about BNP Paribas warrants?</td>\n",
              "      <td>2</td>\n",
              "      <td>404810</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>deepseek</td>\n",
              "      <td>What about BNP Paribas warrants?</td>\n",
              "      <td>3</td>\n",
              "      <td>404820</td>\n",
              "      <td>546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>730 rows √ó 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fbf8bb0-6d81-4be9-833c-2079397198fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fbf8bb0-6d81-4be9-833c-2079397198fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fbf8bb0-6d81-4be9-833c-2079397198fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-821579d1-fab5-4c0d-ae4a-83fbce25a612\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-821579d1-fab5-4c0d-ae4a-83fbce25a612')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-821579d1-fab5-4c0d-ae4a-83fbce25a612 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_16fe3ba8-5a0a-40db-bf85-c317bb1bc644\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16fe3ba8-5a0a-40db-bf85-c317bb1bc644 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 730,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"claude\",\n          \"deepseek\",\n          \"mistral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"What is Call to Action?\",\n          \"How to activate Music Streaming?\",\n          \"How to open another mailbox?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Document ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1885,\n        \"min\": 398400,\n        \"max\": 404820,\n        \"num_unique_values\": 141,\n        \"samples\": [\n          401420,\n          403110,\n          399620\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 189,\n        \"min\": 21,\n        \"max\": 1244,\n        \"num_unique_values\": 115,\n        \"samples\": [\n          113,\n          256,\n          217\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_word_count(df):\n",
        "    \"\"\"\n",
        "    Categorizes an existing word_count column as 'short', 'medium', or 'long'\n",
        "    within each Model and Query group based on relative length.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): DataFrame with 'word_count', 'Model', and 'Query' columns\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: DataFrame with 'length_category' column added\n",
        "    \"\"\"\n",
        "    result_df = df.copy()\n",
        "\n",
        "    # Define the length categories\n",
        "    length_categories = ['short', 'medium', 'long']\n",
        "\n",
        "    # Sort and assign length categories within each group\n",
        "    result_df['length_category'] = (\n",
        "        result_df.sort_values(by='word_count', ascending=True)\n",
        "        .groupby(['Model', 'Query'])\n",
        "        .cumcount()\n",
        "        .apply(lambda x: length_categories[min(x, len(length_categories)-1)])\n",
        "    )\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "cQmi0alrTGJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = categorize_word_count(df)"
      ],
      "metadata": {
        "id": "-sWKRbCOTXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the plot grid: 2x2 for ranks 1 to 4\n",
        "fig, axes = plt.subplots(3, 1, figsize=(8, 15))\n",
        "#fig.suptitle(\"Length Category Distribution by Model for Each Rank\", fontsize=16)\n",
        "\n",
        "# Flatten axes array for easy indexing#\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through Rank 1 to 3\n",
        "for rank in range(1, 4):\n",
        "    ax = axes[rank - 1]\n",
        "    subset = df[df[\"Rank\"] == rank]\n",
        "    sns.countplot(data=subset, x=\"length_category\", hue=\"Model\", order=[\"long\", \"medium\", \"short\"], ax=ax, palette=model_palette)\n",
        "    ax.set_title(f\"Rank {rank}\")\n",
        "    ax.set_xlabel(\"Length Category\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "\n",
        "# Improve layout\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "fig.savefig(\"retrieval_length_distribution.png\", dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "id": "nwQAKXhDHo0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "\n",
        "def perform_chi2_per_rank_length(df):\n",
        "    \"\"\"\n",
        "    Performs Chi-Square test of independence between Model and Length Category\n",
        "    for each rank in the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'Model', 'Rank', and 'length_category' columns\n",
        "                           ('long', 'medium', 'short').\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are ranks and values are the Chi-Square\n",
        "              test results.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for rank in sorted(df['Rank'].unique()):\n",
        "        rank_df = df[df['Rank'] == rank]\n",
        "        contingency_table = pd.crosstab(rank_df['Model'], rank_df['length_category'])\n",
        "        if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:\n",
        "            chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "            results[f\"Rank {rank}\"] = {'Chi2 Statistic': chi2,\n",
        "                                       'P-value': p,\n",
        "                                       'Degrees of Freedom': dof,\n",
        "                                       'Expected Frequencies': expected}\n",
        "        else:\n",
        "            results[f\"Rank {rank}\"] = \"Insufficient data for Chi-Square test\"\n",
        "    return results\n",
        "\n",
        "def create_contingency_tables_length(df):\n",
        "    \"\"\"\n",
        "    Creates contingency tables of Model vs. Length Category for each rank.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'Model', 'Rank', and 'length_category' columns.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are ranks and values are the\n",
        "              corresponding contingency tables (pd.DataFrame).\n",
        "    \"\"\"\n",
        "    contingency_tables = {}\n",
        "    for rank in sorted(df['Rank'].unique()):\n",
        "        rank_df = df[df['Rank'] == rank]\n",
        "        contingency_tables[f\"Rank {rank}\"] = pd.crosstab(rank_df['Model'], rank_df['length_category'])\n",
        "    return contingency_tables\n",
        "\n",
        "# Perform the Chi-Square tests\n",
        "chi2_length_results = perform_chi2_per_rank_length(df)\n",
        "\n",
        "# Print the results\n",
        "for rank, result in chi2_length_results.items():\n",
        "    print(f\"\\n--- Rank {rank} (Length Bias) ---\")\n",
        "    if isinstance(result, str):\n",
        "        print(result)\n",
        "    else:\n",
        "        print(f\"Chi2 Statistic: {result['Chi2 Statistic']:.4f}\")\n",
        "        print(f\"P-value: {result['P-value']:.4f}\")\n",
        "        print(f\"Degrees of Freedom: {result['Degrees of Freedom']}\")\n",
        "        print(\"Expected Frequencies:\\n\", result['Expected Frequencies'])\n",
        "\n",
        "# Create contingency tables for length bias\n",
        "contingency_tables_length = create_contingency_tables_length(df)\n",
        "\n",
        "# Print the contingency tables\n",
        "print(\"\\n--- Contingency Tables (Model vs. Length Category per Rank) ---\")\n",
        "for rank, table in contingency_tables_length.items():\n",
        "    print(f\"\\nRank {rank}:\\n{table}\")"
      ],
      "metadata": {
        "id": "_PG0VpEsHoxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rPsWVebJHovG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JT5A9c9Hosu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3TPURQ2_HopX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dsP2bIiDHomy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}